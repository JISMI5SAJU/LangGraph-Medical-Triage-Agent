{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3yWWtQ8cC4i"
   },
   "source": [
    "# STEP 0: Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gITT5NMlB-3x"
   },
   "outputs": [],
   "source": [
    "!pip install -qU google-generativeai==0.8.5 google-ai-generativelanguage==0.6.15 \\\n",
    "langgraph langchain langchain-google-genai openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XvoFPl11cFhj"
   },
   "source": [
    "# STEP 1: Imports and secure API key input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ULl9-DXtEfI-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from langgraph.graph import StateGraph,END # Import StateGraph\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W28u20SxcIiH"
   },
   "source": [
    "\n",
    "# Secure Gemini API Key input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tbkm6TjPGQba",
    "outputId": "a70e180a-d912-4176-8375-9c4030622541"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your Gemini API key: ··········\n"
     ]
    }
   ],
   "source": [
    "os.environ['GOOGLE_API_KEY']=getpass.getpass('Enter your Gemini API key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eusINPuVcLXp"
   },
   "source": [
    "# STEP 2: Initialize Gemini 1.5 Flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2vLx79sWJ2ur"
   },
   "outputs": [],
   "source": [
    "llm=ChatGoogleGenerativeAI(model=\"models/gemini-1.5-flash-latest\",temperature=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o07zbkLWcOVW"
   },
   "source": [
    "# STEP 3: Node to ask user for symptom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBWiUdtJKgW6"
   },
   "outputs": [],
   "source": [
    "def get_symptom(state: dict) ->dict:\n",
    "  symptom=input(\"Welcome to XYZ Hospital,Please enter your symptom\")\n",
    "  state[\"symptom\"]=symptom\n",
    "  return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KIzyYPVcRVm"
   },
   "source": [
    "# STEP 4: Node to classify the symptom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4WOPOR0C4cQK"
   },
   "outputs": [],
   "source": [
    "def classify_symptom(state: dict) ->dict:\n",
    "  prompt=(\"You are a helpful Medical Assistant,classify the symptoms below into one of the categories \\n\"\n",
    "           \"-General \\n -Emergency \\n -mental health \\n\"\n",
    "           f\"symptom: {state['symptom']}\\n\"\n",
    "           \"Respond only with one word :General,Emergency or Mental Heath\"\n",
    "           \"#Example :input : I have fever ,Output : General\"\n",
    "  )\n",
    "  response=llm.invoke(prompt)\n",
    "  category=response.content.strip()\n",
    "  print(f\"LLM classifies the symptom as : {category}\")\n",
    "  state[\"category\"]=category\n",
    "  return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kESmxbnicWpS"
   },
   "source": [
    "# STEP 5: Router logic to route to the correct node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zCIUob0F7GdV"
   },
   "outputs": [],
   "source": [
    "def symptom_router(state: dict) ->dict:\n",
    "  cat=state[\"category\"].lower()\n",
    "  if \"general\" in cat:\n",
    "    return \"general\"\n",
    "  elif \"Emergency\" in cat:\n",
    "    return \"Emergency\"\n",
    "  elif \"mental health\" in cat:\n",
    "    return \"Mental Health\"\n",
    "  else:\n",
    "    return \"general\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZuR4VGscake"
   },
   "source": [
    "# STEP 6: Category-specific response nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X5mFCPAp8zyh"
   },
   "outputs": [],
   "source": [
    "def general_node(state: dict) ->dict:\n",
    "  state[\"answer\"] = f\"  '{state['symptom']}' : seems general:directing you to general ward for consulting a doctor\"\n",
    "  return state\n",
    "\n",
    "def emergency_node(state: dict) ->dict:\n",
    "  state[\"answer\"] = f\"  '{state['symptom']}' : it is a medical emergency:seeking immediate medical help\"\n",
    "  return state\n",
    "\n",
    "def mental_health_node(state: dict) ->dict:\n",
    "  state[\"answer\"] = f\"  '{state['symptom']}' : seems like a medical health issue:talk to our counsellor\"\n",
    "  return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1ek0SwzcehS"
   },
   "source": [
    "# STEP 7: Build LangGraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ID5KzV__GOA",
    "outputId": "fb5c3fe9-551b-4710-c038-d4e89a7bd225"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7b0ced0a8850>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the builder\n",
    "builder = StateGraph(dict)\n",
    "\n",
    "# Define all nodes\n",
    "builder.add_node(\"get_symptom\", get_symptom)\n",
    "builder.add_node(\"classify_symptom\", classify_symptom)\n",
    "builder.add_node(\"general\", general_node)\n",
    "builder.add_node(\"Emergency\", emergency_node)\n",
    "builder.add_node(\"Mental Health\", mental_health_node)\n",
    "\n",
    "# Add transitions (edges)\n",
    "builder.add_edge(\"get_symptom\", \"classify_symptom\")\n",
    "\n",
    "builder.add_conditional_edges(\"classify_symptom\", symptom_router, {\n",
    "    \"general\": \"general\",\n",
    "    \"Emergency\": \"Emergency\",\n",
    "    \"Mental Health\": \"Mental Health\"\n",
    "})\n",
    "\n",
    "# Add END nodes\n",
    "builder.add_edge(\"general\", END)\n",
    "builder.add_edge(\"Emergency\", END)\n",
    "builder.add_edge(\"Mental Health\", END)\n",
    "\n",
    "# Set the entry point\n",
    "builder.set_entry_point(\"get_symptom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbAgCeZYci5k"
   },
   "source": [
    "# STEP 8: Compile and invoke the graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9xTwHBaG40w",
    "outputId": "9de4b808-2e38-4c9d-c398-aec6f6421701"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to XYZ Hospital,Please enter your symptomi have dust allergy\n",
      "LLM classifies the symptom as : General\n",
      "final output \n",
      "\n",
      "  'i have dust allergy' : seems general:directing you to general ward for consulting a doctor\n"
     ]
    }
   ],
   "source": [
    "graph = builder.compile()\n",
    "final_state=graph.invoke({})\n",
    "print(\"final output \\n\")\n",
    "print(final_state[\"answer\"])\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
